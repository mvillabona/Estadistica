{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22zXjFMRkUkJ"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1XIxF92v5BOrpS63i6FMIXGddxAp8WSHd\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z-u0asqSJS9"
      },
      "source": [
        "# **Modelado estadístico con *Python***\n",
        "---\n",
        "En este notebook presentaremos los conceptos fundamentales y las herramientas para realizar **análisis de correlaciones** y **análisis de regresiones** con *Python*.\n",
        "\n",
        "Para realizar este tipo de análisis estadísticos avanzados usando *Python* usaremos principalmente dos librerías especializadas: **`scipy`** y **`statsmodels`**.\n",
        "\n",
        "<img src=\"https://github.com/scipy/scipy.org/blob/main/static/images/logo.svg?raw=true\" alt=\"scipy\" width=\"15%\">\n",
        "<img src=\"https://www.statsmodels.org/stable/_images/statsmodels-logo-v2-horizontal.svg\" alt=\"statsmodels\" width=\"45%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3wRdctX8zjR"
      },
      "source": [
        "from scipy import stats\n",
        "import scipy\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XQA3OMRiGj"
      },
      "source": [
        "# Otras librerías de utilidad.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib se verá en los recursos de la Unidad 4.\n",
        "import matplotlib  \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIRLOqN-hwtg"
      },
      "source": [
        "# Para verificar las versiones de las librerías\n",
        "\n",
        "!python --version\n",
        "print('SciPy', scipy.__version__)\n",
        "print('statsmodels', sm.__version__)\n",
        "print('Pandas', pd.__version__)\n",
        "print('NumPy', np.__version__)\n",
        "print('Matplotlib', matplotlib.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhUQVgwdiH6U"
      },
      "source": [
        "**Versiones utilizadas:**\n",
        "\n",
        "\n",
        "*   **`Python`**: 3.6.9\n",
        "*   **`SciPy`**: 1.4.1\n",
        "*   **`statsmodels`**: 0.10.2 \n",
        "*   **`Pandas`**: 1.1.5\n",
        "*   **`NumPy`**: 1.19.5\n",
        "*   **`Matplotlib`**: 3.2.2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyyYqzShjxwL"
      },
      "source": [
        "# **1. Análisis de correlación**\n",
        "---\n",
        "El análisis de correlación es el proceso estadístico en el que se busca identificar asociaciones (relaciones o dependencias) entre dos variables. Estas relaciones se cuantifican con coeficientes de correlación, que representan numéricamente el grado de relación entre las variables analizadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lybakBRGIve2"
      },
      "source": [
        "## **1.1 Coeficientes de correlación**\n",
        "---\n",
        "\n",
        "Los **coeficientes de correlación** pueden tener valores de entre $-1.0$ y $1.0$. Una correlación positiva significa que las variables tienen una relación directa, mientras que una correlación negativa indica que las variables tienen una relación inversa entre sí. Mientras más cerca está de los extremos $-1.0$ y $1.0$, mayor es la fuerza de la correlación. Los valores cercanos a $0.0$ manifiestan una correlación lineal nula entre las variables.\n",
        "\n",
        "Existen 3 tipos de coeficientes de correlación:\n",
        "* **Coeficiente de correlación $r$ de Pearson**: Es el coeficiente de correlación **más utilizado**, y de especial utilidad con **variables cuantitativas**. Es un método paramétrico, y por lo tanto, depende del supuesto de que los datos tienen una **distribución normal y varianzas homogéneas**. Es especialmente sensible a valores atípicos, por lo que se recomienda limpiar adecuadamente los datos.\n",
        "* **Coeficiente de correlación $\\rho$ de Spearman**: Es un método no-paramétrico, de utilidad con **variables categóricas ordinales** o **variables numéricas**. Su cálculo es muy similar al coeficiente de Pearson, agregando consideraciones adicionales en el uso de variables de rango. Los datos pueden ser no normalmente distribuidos y no haber homogeneidad de varianzas.\n",
        "* **Coeficiente de correlación $\\tau$ de Kendall**: Es un método no-paramétrico usado en **variables categóricas ordinales**. Se basa en la correspondencia entre el orden de cada pareja de observaciones. Debido a esto es más costoso a nivel computacional, pero más robusto en algunos casos. No realiza ninguna suposición sobre la distribución de los datos. La única suposición es que existe una relación monotónica entre las variables probadas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aditTjnEocN"
      },
      "source": [
        "### **1.1.1. Usando `Pandas`**\n",
        "---\n",
        "\n",
        "En *Python* es posible hacer análisis de correlación usando *NumPy*, *pandas* y *SciPy*, principalmente. Usando ***pandas*** se pueden llevar acabo análisis básicos por medio de las siguientes funciones, vistas en la unidad anterior:\n",
        "\n",
        "* [**`pd.Series.corr`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.corr.html): Calcula el coeficiente de correlación con otra **`Series`** de *pandas*, excluyendo los valores faltantes. Recibe como parámetro el método usado (**`'pearson', 'kendall', 'spearman'`**).\n",
        "\n",
        "* [**`pd.DataFrame.corrwith`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corrwith.html): Calcula la correlación uno a uno entre las filas o columnas de un **`DataFrame`** de *pandas* con las filas o columnas de otra **`Series`** u otro **`DataFrame`**. Recibe como parámetro el método usado (**`'pearson', 'kendall', 'spearman'`**).\n",
        "\n",
        "* [**`pd.DataFrame.corr`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html): Calcula la matriz de correlación entre las columnas de un **`DataFrame`** de *pandas*, excluyendo los valores nulos o faltantes. Recibe como parámetro el método usado (**`'pearson', 'kendall', 'spearman'`**).\n",
        "\n",
        "Más adelante en este Notebook veremos otros análisis más avanzados usando *SciPy*. Por el momento, veamos algunos ejemplos usando *pandas*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImcG6OzbIfLC"
      },
      "source": [
        "Inicialmente vamos a trabajar con los siguientes datos de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRWUtg2PE3u1"
      },
      "source": [
        "np.random.seed(1) # Para que siempre genere los mismos números aleatorios\n",
        "\n",
        "var1 = pd.Series(range(10))\n",
        "var2 = pd.Series(range(10,0,-1))\n",
        "var3 = pd.Series(np.random.randint(0,10,10))\n",
        "var4 = pd.Series(np.random.randint(0,10,10))\n",
        "\n",
        "df = pd.DataFrame(data={'var1':var1, 'var2':var2, \n",
        "                        'var3':var3, 'var4':var4, })\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7_3EOEtIbZ5"
      },
      "source": [
        "**Correlación positiva perfecta**: Cuando una variable se incrementa la otra también, en la misma medida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPGu4-ivIydd"
      },
      "source": [
        "# Correlación de var1 con ella misma = 1.0\n",
        "\n",
        "r = var1.corr(var1) # Método Pearson por defecto\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Aag_0MJa2E"
      },
      "source": [
        "Se recomienda siempre visualizar los datos para poder interpretar los resultados de las correlaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmO17tGpJig8"
      },
      "source": [
        "def graficar_correlación(df, var_a, var_b):\n",
        "\n",
        "  r = df[var_a].corr(df[var_b]);\n",
        "  fig, ax = plt.subplots(dpi = 110);\n",
        "  df.plot.scatter(var_a, var_b, title=f\"Coeficiente de correlación: {r :.2}\", ax = ax,\n",
        "                marker='o', linestyle='None', s = 70, alpha = 0.5, grid=True # Parámetros de estilo (Más información en la Unidad 4 y 5)\n",
        "                ); \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRSSLsS1UVbQ"
      },
      "source": [
        "graficar_correlación(df, 'var1', 'var1');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCc_fYP8KTco"
      },
      "source": [
        "**Correlación negativa perfecta**: Cuando una variable se incrementa la otra disminuye, en la misma medida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lSWOiiyJZLt"
      },
      "source": [
        "# Correlación de var1 con respecto a var2 = -1.0 (aprox)\n",
        "r = var1.corr(var2) # Método Pearson por defecto\n",
        "\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBtRos-rJTJs"
      },
      "source": [
        "graficar_correlación(df, 'var1', 'var2');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhtcXfaHMF9z"
      },
      "source": [
        "**Correlación nula**: Las variables no presentan una correlación lineal entre sí."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlo5g73MF93"
      },
      "source": [
        "# Correlación de var1 con respecto a var3 = 0.0 (aprox)\n",
        "r = var1.corr(var3) # Método Pearson por defecto\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNratlIvMF96"
      },
      "source": [
        " graficar_correlación(df, 'var1', 'var3');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwDlux9wQkH8"
      },
      "source": [
        "**Correlación positiva alta**: Cuando una variable se incrementa la otra también, no necesariamente la misma medida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuholxPQZVE"
      },
      "source": [
        "# Correlación de var1 con respecto a var4 = 0.75 (aprox)\n",
        "r = var1.corr(var4) # Método Pearson por defecto\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuWA5N8KQZVH"
      },
      "source": [
        "graficar_correlación(df, 'var1', 'var4');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oeukrhAVZT1"
      },
      "source": [
        "**Análisis de correlación entre múltiples variables**\n",
        "\n",
        "---\n",
        "\n",
        "Muchas veces es necesario analizar las correlaciones existentes entre múltiples variables al mismo tiempo. Para esto podemos hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsnDaQ7nK5M-"
      },
      "source": [
        "# Correlación de cada columna de \"df\" con respecto a la Serie \"var1\"\n",
        "\n",
        "df.corrwith(var1) # Método Pearson por defecto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cUlRs1nWAxc"
      },
      "source": [
        "# Correlación de cada columna de \"df\" con respecto a la Serie \"var4\"\n",
        "df.corrwith(var4) # Método Pearson por defecto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFfdau2SWHM_"
      },
      "source": [
        "También, es posible calcular la matriz de correlación de un **`DataFrame`**. De esta forma podemos explorar todas las posibles correlaciones entre las variables numéricas que componen el conjunto de datos. Esto es muy útil para hacer análisis de asociaciones en *datasets* reales: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7DW8eONIr9s"
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBRxQcvMW64R"
      },
      "source": [
        "En cada celda nos informa cuál es el coeficiente de correlación de la combinación de variables dada por las fila y columna seleccionada. Además, note que el resultado es otro *DataFrame* que podemos manipular, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYLso89LWrsE"
      },
      "source": [
        "matriz_corr = df.corr()\n",
        "matriz_corr['var4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoJ4UWGCXZVD"
      },
      "source": [
        "matriz_corr.loc['var2','var4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQES4VVUZDH3"
      },
      "source": [
        "### **1.1.2. Usando `NumPy`**\n",
        "---\n",
        "En caso que nuestros datos estén en forma de arreglos de *NumPy*, podemos hacer el mismo análisis anterior usando la función **`np.corrcoef`**:\n",
        "\n",
        "* [**`np.corrcoef`**](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html): Retorna la matriz de correlación entre las variables (coeficiente de correlación de *Pearson*).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUQlS87-X1gG"
      },
      "source": [
        "np.random.seed(1) # Para que siempre genere los mismos números aleatorios y/o reiniciar la semilla\n",
        "\n",
        "arr1 = np.array(range(10))\n",
        "arr2 = np.array(range(10,0,-1))\n",
        "arr3 = np.array(np.random.randint(0,10,10))\n",
        "arr4 = np.array(np.random.randint(0,10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r38ID1hGYDeE"
      },
      "source": [
        "np.corrcoef(arr1, arr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFyr2kn5ZYor"
      },
      "source": [
        "np.corrcoef(arr1, [arr2, arr3, arr4],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtyrgAIl5RSm"
      },
      "source": [
        "## **1.2. Valores atípicos**\n",
        "---\n",
        "\n",
        "El coeficiente de correlación es muy sensible a valores de datos atípicos o outliers. Es muy importante realizar una correcta limpieza de los datos antes de hacer este tipo de análisis.\n",
        "\n",
        "Por ejemplo, suponga que tenemos dos variables con los siguientes datos y queremos conocer su correlación:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZNuLtN8c5BD"
      },
      "source": [
        "var1 = np.array([ -4.6,  -7. ,   2. ,  -3.4,   1.1,  -5.9,   2.2,   1.8,  -8.9, 1.5,   1.4,   2.5,   3.9,   8.4,  -8. ,   2.3,  -2.8,   0.6,\n",
        "        -2.8,   3.3,   4.3,  -1.3,  -3.9,   0.5,   3.5,   2. ,   8.5, -7.6,   1.1,   5.8,  -2.4,  -3.8,   3.8,   0.5,  -3.5,  -7.7,\n",
        "        -2.1,  -9.7,   1.3,   3.7,   3.1,   0.7,   2.1,  -3.6,   5.8, -10.5,   5.6,  -2.2,  -0.9,   0.8,   3.4,  -6.2,  -5.3,   1.9,\n",
        "         2.1,   0.6,   3.2,   4.5,  -4.1,  -4.1,   4. ,  -2.2,  -2.5, -4.3,  -0.3,  -5.2,  -4.3,  -5.4,  -5.3,   2.7,   1.2,   4.2,\n",
        "        -3.4,   1.8,  -1.6,  -5.3,   3.7,  -0.7,   6.3,  -0.9,   2.2, -7.1,  -2.4,   1.1, -13.3,  -6.1,   6.6,  -0.1,  -0.3,   0.1,\n",
        "        -1.6,   3. ,   7.1,  -7. ,   7.6,  -0.6,  -3.1,  -9.6,   4.2, 4.9,   9. ,  10.1,  10.5,  10.2])\n",
        "var2 = np.array([ -4.6,  -8.9,   1.4,  -1.1,   0.9,  -5.9,   1.9,   2.1,  -8.1, 2.1,   0.6,   3.9,   3.1,   7.6,  -7.1,   4.9,  -3.2,  -1.1,\n",
        "        -1.9,   5.8,   4.1,  -1.8,  -5.1,  -1.2,   3. ,   2.4,   8.4, -5.9,   2. ,   4.5,  -2.9,  -3.9,   4.5,  -0.8,  -2.8,  -7.9,\n",
        "        -1.5,  -9.6,   2.6,   3.1,   3.8,   1.6,   3.2,  -3.3,   4.6, -11.7,   4.3,  -3.7,  -1.2,   0.7,   0.9,  -6.7,  -4.9,   0.8,\n",
        "         3. ,   0.2,   1.6,   3.7,  -2.9,  -2.9,   5.2,  -2.1,  -2.4, -4.6,  -1.7,  -5.3,  -3.6,  -6.3,  -4.7,   3.2,   1.4,   4.9,\n",
        "        -2.2,  -0.4,  -1.5,  -5.4,   2.8,   0.7,   6.2,  -0.3,   2.4, -7. ,  -1.6,   0.2, -11.3,  -8.1,   6.8,   0.1,  -1. ,   0.8,\n",
        "        -1. ,   2.8,   7.6,  -5.5,   6.3,  -0.3,  -4.5,  -9.1,   4.5, 4.3, -11.4, -12.3, -11.4, -11.9])\n",
        "df = pd.DataFrame(data={'var1':var1, 'var2':var2})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j3_J9C3eiLS"
      },
      "source": [
        "Vamos a calcular el coeficiente de correlación entre las dos variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRgaa28Cemku"
      },
      "source": [
        "r = df['var1'].corr(df['var2']) # Método Pearson por defecto\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP7dkfOxfWQJ"
      },
      "source": [
        "Obtenemos una correlación moderada entre las variables ($r = 0.62$). Sin embargo, queremos verificar este resultado por medio de un diagrama de dispersión entre las variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERI2I3NBdU6s"
      },
      "source": [
        "df.plot.scatter('var1', 'var2', title=f'Correlación con outliers: {r:.2}',\n",
        "                     s = 70, alpha = 0.6, color = '#35bacc', figsize = (7,5));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKuE4oLhgA9F"
      },
      "source": [
        "Como se puede apreciar, existen valores atípicos en la equina inferior derecha. Primero, vamos a localizar los puntos problemáticos para volverlos a visualizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKOQrGkgd8s"
      },
      "source": [
        "outliers = df[(df['var1'] >= 9.0) & (df['var2'] < -11)]\n",
        "outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf5UTrswgNcD"
      },
      "source": [
        "# Usamos ax para hacer las dos figuras en la misma gráfica\n",
        "ax = df.plot.scatter('var1', 'var2', title= f'Correlación con outliers: {r:.2}',\n",
        "                     s = 70, alpha = 0.6, color = '#35bacc', figsize = (7,5))\n",
        "outliers.plot.scatter('var1', 'var2', s = 70, alpha = 0.8, color = '#f96340', ax = ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yapG-GqGhwfw"
      },
      "source": [
        "Si la naturaleza de los datos lo permite, vamos a limpiar estos datos atípicos de nuestro conjunto de datos para hacer el análisis de correlación nuevamente sin estos datos: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-n_ad01iKHb"
      },
      "source": [
        "# Construimos una máscara para filtrar los valores atípicos\n",
        "mask = df.isin(outliers)\n",
        "df_limpio = df.mask(mask).dropna() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9FgqRjbklek"
      },
      "source": [
        "Nuevamente, calculamos el coeficiente de correlación entre las dos variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swN-rEjdklel"
      },
      "source": [
        "r = df_limpio['var1'].corr(df_limpio['var2']) # Método Pearson por defecto\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1DBNB03klep"
      },
      "source": [
        "Observe que el coeficiente se incrementó considerablemente ($r = 0.97$). Veamos el nuevo diagrama de dispersión entre las variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qltfMs_kleq"
      },
      "source": [
        "df_limpio.plot.scatter('var1', 'var2', title= f'Correlación sin outliers: {r:.2}',\n",
        "                     s = 70, alpha = 0.6, color = '#35bacc', figsize = (7,5));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI9J7AbBlpx_"
      },
      "source": [
        "> **Nota:** De esta forma, podemos identificar una relación mucho más directa que la que habíamos podido identificar antes de limpiar el conjunto de datos. No obstante, tenga en cuenta que la posibilidad de limpiar los valores atípicos depende del entendimiento que tengamos de los datos. Debemos estar seguros de estar haciendo lo correcto al manipular los datos, en este caso, eliminando *outliers*. De lo contrario, podríamos estar manipulando los resultados de manera indeseada, sin reflejar la naturaleza real de la relación entre las variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9sZYQ6B1U0J"
      },
      "source": [
        "## **1.3. Significancia estadística**\n",
        "---\n",
        "\n",
        "Como hemos visto, los coeficientes de correlación permiten cuantificar la relación entre variables. Al igual que con otras estimaciones, el cálculo de los coeficientes de correlación se apoya en la estadística inferencial para establecer los niveles de significancia de estas relaciones. Al realizar análisis de correlaciones es muy importante reportar los **p-valores** de las correlaciones para evitar señalar relaciones que puedan haberse producido por la aleatoriedad de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnM9WVDDEtHx"
      },
      "source": [
        "**Usando `SciPy`**\n",
        "***\n",
        "\n",
        "Si deseamos conocer el **p-valor** de una correlación usando *Python* debemos utilizar las siguientes funciones de la librería *SciPy*:\n",
        "\n",
        "* [**`stats.pearsonr`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html): coeficiente de correlación $r$ de Pearson.\n",
        "* [**`stats.spearmanr`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html): coeficiente de correlación $\\rho$ de Spearman.\n",
        "* [**`stats.kendalltau`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html): coeficiente de correlación $\\tau$ de Kendall.\n",
        "\n",
        "Estas funciones reciben como parámetros los arreglos **`x`** y **`y`**, y retornan:\n",
        "* El coeficiente de correlación correspondiente.\n",
        "* El **p-valor** para un test de hipótesis cuya hipótesis nula es que los datos no están correlacionados. Por lo tanto, si el **p-valor $\\lt \\alpha$** (nivel de significancia), esto quiere decir que la correlación es significativa. De lo contrario, la correlación puede deberse a la aleatoriedad de los datos, independientemente de su valor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSraMoiidV2g"
      },
      "source": [
        "#### **1.3.1. Coeficiente de correlación de Pearson**\n",
        "---\n",
        "\n",
        "Suponga que queremos calcular el coeficiente de correlación y el **p-valor** de la relación para los datos del primer ejemplo de este notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD4CtEpNdbiR"
      },
      "source": [
        "np.random.seed(1) # Para que siempre genere los mismos números aleatorios y/o reiniciar la seed.\n",
        "\n",
        "var1 = pd.Series(range(10))\n",
        "var2 = pd.Series(range(10,0,-1))\n",
        "var3 = pd.Series(np.random.randint(0,10,10))\n",
        "var4 = pd.Series(np.random.randint(0,10,10))\n",
        "\n",
        "df = pd.DataFrame(data={'var1':var1, 'var2':var2, \n",
        "                        'var3':var3, 'var4':var4, })\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dN6Y5YJeWlP"
      },
      "source": [
        "Vamos a declarar una función que calcula la correlación de Pearson y, además, interpreta el resultado del p-valor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yf6YP6vefeK"
      },
      "source": [
        "def correlacion_pearson_con_significancia(x, y, alfa=0.05):\n",
        "  coef, p = stats.pearsonr(x, y)\n",
        "  print(f'Coeficiente de correlación de Pearson: {coef:.2f}')\n",
        "  if p > alfa:\n",
        "    print(f'Las muestras no están correlacionadas (no rechazar H0) (p = {p:.2f})')\n",
        "  else:\n",
        "    print(f'Las muestras están correlacionadas (rechazar H0) (p = {p:.2f})')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSlsyUtSfLR7"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var1'], df['var2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg036bbDfTKD"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var1'], df['var3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJJV6FmLfViq"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var1'], df['var3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN9k2e-vfYdb"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var1'], df['var4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_djusxi0dnW8"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var3'], df['var4'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ1JnyAAfkqg"
      },
      "source": [
        "Observe que en este último caso, aunque el coeficiente de correlación era $r=0.56$, lo cual indica una relación moderada aparente entre `var3` y `var4` , el **p-valor** $= 0.091$ está por encima del nivel de significancia. Por lo tanto, podemos afirmar que la correlación NO es significativa, es decir, que no se rechaza la hipótesis nula. En otras palabras, esta correlación puede estar causada por la aleatoriedad de los datos, y no por una relación entre ambas variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBl-pppTqBr_"
      },
      "source": [
        "#### **1.3.2. Coeficiente de correlación de Spearman**\n",
        "---\n",
        "\n",
        "Para este ejemplo, vamos a generar los siguientes datos artificiales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUTtAChDZcI9"
      },
      "source": [
        "data1 = np.linspace(0, 2*np.pi, 20)\n",
        "data2 = 10*np.sin(data1) + np.pi*np.arange(20)\n",
        "\n",
        "df = pd.DataFrame(data={'var1':data1, 'var2':data2})\n",
        "\n",
        "# Graficamos los datos\n",
        "df.plot.scatter('var1', 'var2', s = 50, alpha = 0.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H4srzTaqihG"
      },
      "source": [
        "Si calculamos el coeficiente de correlación de Pearson:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AmBRlxwcfSd"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['var1'], df['var2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dobovCzqzdx"
      },
      "source": [
        "Obtenemos un coeficiente de correlación muy alto ($r = 0.94$) y un **p-valor** $=0$, indicando un alto nivel de significancia estadística. Sin embargo, estas variables no cumplen el supuesto de homocedasticidad, es decir, las muestras no tienen varianzas homogéneas. Esto se puede comprobar con la prueba de **`Levene`** que tiene como hipótesis nula que las muestras tienen varianza homogéneas, y es una prueba de una sola cola:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Ql3MyVrdwz"
      },
      "source": [
        "stat, pvalor = stats.levene(df['var1'], df['var2'])\n",
        "if pvalor < 0.05:  \n",
        "  print(f'Las muestras no tienen varianzas homogéneas (rechazar H0) p = {pvalor:.3f}')\n",
        "else:\n",
        "  print(f'Las muestras tienen varianza homogéneas (no rechazar H0) p = {pvalor:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyjc-6qLsytM"
      },
      "source": [
        "En este caso, entonces, lo más adecuado será utilizar el coeficiente de correlación de **Spearman**. Esto también ocurre **cuando una de las muestras no está distribuida normalmente**. Además, este método es capaz de capturar de mejor manera la [relación monótona](https://es.wikipedia.org/wiki/Funci%C3%B3n_mon%C3%B3tona) entre las dos variables de este ejemplo, veamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1n0ug5od782"
      },
      "source": [
        "def correlacion_spearmanr_con_significancia(a, b):\n",
        "  coef, p = stats.spearmanr(a, b)\n",
        "  print(f'Coeficiente de correlación de Spearman: {coef:.2f}')\n",
        "\n",
        "  if p > 0.05:\n",
        "    print(f'Las muestras no están correlacionadas (no rechazar H0) p = {p:.3f}')\n",
        "  else:\n",
        "    print(f'Las muestras están correlacionadas (rechazar H0) p = {p:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aufZfAU1cfSj"
      },
      "source": [
        "correlacion_spearmanr_con_significancia(df['var1'], df['var2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc-BUhB_t3BM"
      },
      "source": [
        "Observe que en este caso la correlación no sólo es significativa, sino que el coeficiente $\\rho$ de Spearman alcanzó un valor de $0.99$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t65qiaY_uLx8"
      },
      "source": [
        "#### **1.3.3. Coeficiente de correlación de Kendall**\n",
        "---\n",
        "\n",
        "Por último, recordemos que el coeficiente de *Kendall* es un método no-paramétrico usado en variables categóricas ordinales. Se basa en la correspondencia entre el orden de cada pareja de observaciones. No realiza ninguna suposición sobre la distribución de los datos. La única suposición es que existe una relación monótona entre las variables probadas. Esta prueba es de dos colas, por lo que la significancia se debe dividir entre dos para compararlo contra el p-valor. Por lo tanto, podemos utilizar este método para establecer relaciones entre rankings.\n",
        "\n",
        "> **Ejemplo:** Suponga que una empresa contrata a dos expertos para evaluar la calidad de un conjunto de piezas publicitarias que ha desarrollado y desea seleccionar las mejores. Para esto, a cada experto se le presenta cada una de las piezas publicitarias en el mismo orden y ellos deben seleccionar una única opción con respeto a qué tan de acuerdo o qué tan desacuerdo están con la siguiente afirmación:\n",
        ">\n",
        "> \"*Esta pieza publicitaria es efectiva para conseguir el objetivo de la campaña.*\"\n",
        "\n",
        "Las opciones disponibles están dadas en una [escala Likert](https://es.wikipedia.org/wiki/Escala_Likert), de la siguiente manera: \n",
        "\n",
        "1. Totalmente en desacuerdo\n",
        "2. En desacuerdo\n",
        "3. Ni de acuerdo ni en desacuerdo\n",
        "4. De acuerdo\n",
        "5. Totalmente de acuerdo\n",
        "\n",
        "Nótese que las respuestas de cada uno de los expertos pueden ser consideradas como **variables categóricas ordinales**. \n",
        "\n",
        "> **Pregunta**: Antes de elegir la mejor pieza publicitaria, la empresa está interesada en conocer: ¿en qué medida coincidió el criterio de ambos expertos en las puntuaciones seleccionadas? Al tratarse de valores ordinales, no existe un punto de comparación absoluto entre ambas variables, pero sí en el orden en que están organizadas. Por ejemplo, a lo que el experto 1 pudo haber contestado con la opción 4, quizás el experto 2 generalmente contestaba con la opción 5.\n",
        "\n",
        "Supongamos que los resultados de la evaluación de los expertos son los siguientes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QK-88xyz_mv"
      },
      "source": [
        "items = pd.Series(range(1,11))\n",
        "\n",
        "experto1 = pd.Series([5, 3, 4, 1, 1, 2, 3, 5, 1, 4])\n",
        "experto2 = pd.Series([4, 3, 5, 2, 3, 4, 4, 5, 2, 4])\n",
        "\n",
        "df = pd.DataFrame(data={'item':items, 'experto1':experto1, 'experto2':experto2})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_eNo9Wi4rVF"
      },
      "source": [
        "Calculamos el coeficiente de correlación $\\tau$ de Kendall:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB7ams-6cfSn"
      },
      "source": [
        "coef, p = stats.kendalltau(df['experto1'], df['experto2'])\n",
        "\n",
        "print(f'Coeficiente de correlación de Kendall: {coef:.2f}')\n",
        "if p > 0.05/2.0:\n",
        "  print(f'Las muestras no están correlacionadas (no rechazar H0) p = {p:.3f}')\n",
        "else:\n",
        "  print(f'Las muestras están correlacionadas (rechazar H0) p = {p:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUA1HXWm1elg"
      },
      "source": [
        "Esto quiere decir que, con un $95\\%$ de confianza (como se dijo anteriormente, es una prueba de dos colas), podemos afirmar que el criterio de evaluación de los expertos coincidió con un coeficiente de correlación moderado alto ($0.72$), y se puede proceder a seleccionar la campaña mejor punteada por los expertos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL-U5NO57Xqs"
      },
      "source": [
        "## **1.4. Correlaciones no lineales**\n",
        "---\n",
        "Un coeficiente de correlación bajo no implica que no exista relación entre las variables. Las variables pueden tener una relación no lineal que no sea detectada con los coeficientes de correlación típicos. Se recomienda que siempre verifique por medio de gráficos de dispersión o de líneas. \n",
        "\n",
        "Por ejemplo, si los datos tuvieran la siguiente relación:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaKa7ZCz4yHj"
      },
      "source": [
        "x = np.arange(-100,101)\n",
        "y = x**2 - x  # Función cuadrática\n",
        "df = pd.DataFrame(data={'x':x, 'y':y})\n",
        "\n",
        "# Graficamos los datos\n",
        "df.plot.scatter('x', 'y', s = 20, alpha = 0.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwUQQEWS4yHo"
      },
      "source": [
        "Si calculamos el coeficiente de correlación de Pearson:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRB-w-8W4yHo"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['x'], df['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksLMmpMU5PAZ"
      },
      "source": [
        "Si calculamos el coeficiente de correlación de *Spearman*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqV0V80g5MDJ"
      },
      "source": [
        "correlacion_spearmanr_con_significancia(df['x'], df['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgwfMOgN5X_T"
      },
      "source": [
        "En ambos casos el resultado muestra un coeficiente de correlación cercano a $0.0$ y su p-valor indica que las muestras no están correlacionadas. Sin embargo, como se puede apreciar, aunque la relación entre las variables no es lineal, si hay una clara relación entre ellas dada por la ecuación: $y = x^2 - x$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Tb9cBeU6dHI"
      },
      "source": [
        "Veamos otro ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgx9o5FN6bay"
      },
      "source": [
        "x = np.arange(-3.5, 3.5, 0.01)\n",
        "y = x**4 - 10*x**2 - 2 # Función polinómica\n",
        "df = pd.DataFrame(data={'x':x, 'y':y})\n",
        "\n",
        "# Graficamos los datos\n",
        "df.plot.scatter('x', 'y', s = 2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqoHIOh7soQ"
      },
      "source": [
        "Si calculamos el coeficiente de correlación de *Pearson*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3OzoUhc7soS"
      },
      "source": [
        "correlacion_pearson_con_significancia(df['x'], df['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYUZCvOa7sog"
      },
      "source": [
        "Si calculamos el coeficiente de correlación de Spearman:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngt5AnD_7sog"
      },
      "source": [
        "correlacion_spearmanr_con_significancia(df['x'], df['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_iEhq_u7soh"
      },
      "source": [
        "En ambos casos el resultado es que el coeficiente de correlación es $0.0$ y su p-valor indica que las muestras no están correlacionadas. Sin embargo, como se puede apreciar, aunque la relación entre las variables no es lineal, si hay una clara relación entre ellas dada por la ecuación: $y = x^4 - 10x^2-2$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTJEul2yazGO"
      },
      "source": [
        "# **2. Análisis de regresión**\n",
        "---\n",
        "El análisis de regresión es el proceso estadístico en el que se busca modelar o definir relaciones y asociaciones específicas entre variables. A diferencia del análisis de correlación, con la regresión se definen funciones matemáticas que permiten predecir el valor de una variable dependiente a partir de una o varias variables independientes.  \n",
        "\n",
        "En la regresión se define una variable dependiente de una o más variables distintas, entre las que pudo haber algún tipo de control en la medición. En muchos casos, el análisis de regresión lineal pasa por un análisis previo de correlación.\n",
        "\n",
        "En este Notebook veremos cómo hacer regresiones de los siguientes tipos:\n",
        "\n",
        "* Regresión lineal.\n",
        "* Regresión multilineal.\n",
        "* Regresión logística.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XYsDbT4-aig"
      },
      "source": [
        "## **2.1. Datos**\n",
        "---\n",
        "\n",
        "Para los siguientes ejemplos trabajaremos con el dataset **`Framingham`**. Este conjunto de datos está disponible públicamente en el sitio web de [Kaggle](https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression), y es de un estudio de riesgo cardiovascular sobre los residentes de la ciudad de Framingham, Massachusetts en Estados Unidos. El objetivo de la clasificación es predecir si el paciente tiene un riesgo de 10 años de padecer una futura enfermedad coronaria (CHD). El conjunto de datos proporciona la información de los pacientes con más de 3.000 registros y 15 atributos. Se incluyen diferentes variables con factores de riesgo potenciales a nivel demográficos, comportamentales y médicos.\n",
        "\n",
        "**Demográficos:**\n",
        "* **`male`**: Masculino o femenino (Nominal).\n",
        "* **`age`**: Edad del paciente (aunque las edades registradas han sido truncadas a números enteros, el concepto de edad es continuo).\n",
        "\n",
        "**Comportamiento:**\n",
        "* **`currentSmoker`**: Si el paciente es o no fumador actualmente (nominal).\n",
        "* **`cigsPerDay`**: El número de cigarrillos que la persona fuma en promedio en un día (puede considerarse continuo, ya que se puede tener cualquier número de cigarrillos, incluso medio cigarrillo).\n",
        "\n",
        "**Historia médica:**\n",
        "* **`BPMeds`**: Si el paciente estaba o no tomando medicamentos para la presión sanguínea (nominal).\n",
        "* **`prevalentStroke`**: Si el paciente ha tenido previamente una apoplejía o no (nominal).\n",
        "* **`prevalentHyp`**: Si el paciente era o no hipertenso (nominal).\n",
        "* **`diabetes`**: Si el paciente tenía o no diabetes (nominal).\n",
        "* **`totChol`**: Nivel de colesterol total (continuo).\n",
        "* **`sysBP`**: Presión sanguínea sistólica (continua).\n",
        "* **`diaBP`**: Presión arterial diastólica (continua).\n",
        "* **`BMI`**: Índice de Masa Corporal - IMC (continuo).\n",
        "* **`heartRate`**: Ritmo cardíaco (continuo).\n",
        "* **`glucose`**: Nivel de glucosa (continuo).\n",
        "\n",
        "**Variable objetivo deseada:**\n",
        "* **`TenYearCHD`**: Riesgo de enfermedad coronaria CHD a 10 años (binario: \"1\", significa \"Sí\", \"0\" significa \"No\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsca2VI8CkL6"
      },
      "source": [
        "Primero, descargamos los datos y limpiamos el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEmNvSdRiPBV"
      },
      "source": [
        "url = \"https://docs.google.com/uc?export=download&id=1z2k_-8DtwRGFZhRlSmJBwLn6d0JdLt_k\"\n",
        "\n",
        "df_cardio=pd.read_csv(url)\n",
        "df_cardio.dropna(axis=0, inplace=True) # Se eliminan registros con valores faltantes\n",
        "df_cardio.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWD2m7OsoZrQ"
      },
      "source": [
        "df_cardio.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUpMXFuk-1kP"
      },
      "source": [
        "## **2.2. Regresión lineal**\n",
        "---\n",
        "\n",
        "La regresión lineal es un modelo estadístico que examina la relación lineal entre dos variables. Este modelo plantea una relación lineal proporcional, en la que si una variable aumenta o disminuye, la otra también varía. El objetivo es entonces encontrar la función matemática que más se ajuste a los datos y minimice el error entre las observaciones iniciales y las predicciones. Uno de los métodos más utilizados en la regresión lineal es el método de mínimos cuadrados ordinarios. \n",
        "\n",
        "<img src = \"https://drive.google.com/uc?export=view&id=1EPBzs6bGpO4AvRU8QQp_ym7aue4IfU5n\" alt = \"Regresión lineal\" width = \"65%\">  </img>\n",
        "\n",
        "En el siguiente ejemplo queremos modelar la relación existente entre la presión sistólica de los pacientes y su edad.\n",
        "\n",
        "Exploremos la relación entre las variables de forma gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmVB1CK3o0jY"
      },
      "source": [
        "df_cardio.plot.scatter('age', 'sysBP', title=\"Presión arterial sistólica vs. Edad\",\n",
        "                s = 10, alpha = 0.3, grid=True); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc47Z-HhFRhX"
      },
      "source": [
        "Antes de modelar la relación entre estas dos variables, inspeccionemos la correlación entre ellas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODg6JqVNpTag"
      },
      "source": [
        "correlacion_pearson_con_significancia(df_cardio['age'], df_cardio['sysBP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxaDdrSoFbHZ"
      },
      "source": [
        "Como se puede ver, existe una correlación leve entre ellas (coeficiente Pearson: $0.39$). Además esta relación es estadísticamente significativa (p-valor $=0$). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLZDnI71E79P"
      },
      "source": [
        "**I. Usando `SciPy`**\n",
        "***\n",
        "\n",
        "La librería *SciPy* permite modelar la regresión lineal mediante la función  **`linregress`**:\n",
        "\n",
        "* [**`scipy.stats.linregress`**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)\n",
        "\n",
        "Esta función recibe las dos variables como parámetro (deben tener la misma longitud) y retorna 5 valores:\n",
        "* Pendiente de la línea de regresión.\n",
        "* Intercepción de la línea de regresión.\n",
        "* Coeficiente de correlación.\n",
        "* p-valor de dos colas para una prueba de hipótesis cuya hipótesis nula es que la pendiente es cero.\n",
        "* Error estándar del gradiente estimado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQgtm-qepkOg"
      },
      "source": [
        "pend, interc, corr, p_valor, error_std = stats.linregress(df_cardio['age'], df_cardio['sysBP'])\n",
        "\n",
        "print(f\"pend = {pend:10f}\")\n",
        "print(f\"interc = {interc:10f}\")\n",
        "print(f\"corr = {corr:10f}\")\n",
        "print(f\"p_valor = {p_valor:10f}\")\n",
        "print(f\"error_std = {error_std:10f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_a0yppwGDiu"
      },
      "source": [
        "Como se puede apreciar el p-valor es igual a $0$ aproximadamente, por lo que se puede decir que el modelo obtenido es estadísticamente significativo.\n",
        "\n",
        "La **pendiente** y el **intercepto** de la regresión nos permiten construir la ecuación general de la recta que mejor describe la relación entre las dos variables:\n",
        "\n",
        "$y = mx + b$\n",
        "\n",
        "Donde: \n",
        "\n",
        "* $m$ = **pendiente**.\n",
        "* $b$ = **intercepto**.\n",
        "\n",
        "Por lo tanto, en nuestro caso:\n",
        "\n",
        "$sysBP = pend * age + interc$\n",
        "\n",
        "A continuación, vamos a añadir este modelo como una nueva columna (**`modeloPresionSis`**) al *DataFrame*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m318VTEwQxQ"
      },
      "source": [
        "df_cardio['modeloPresionSis'] =  pend * df_cardio['age'] + interc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvCdX8IuImI1"
      },
      "source": [
        "Ahora vamos a visualizar nuevamente las variables, pero esta vez incluyendo la recta de la regresión lineal entre ellas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZocZYmFlrBC_"
      },
      "source": [
        "ax = df_cardio.plot.scatter('age', 'sysBP', title=\"Presión arterial sistólica vs. Edad\",\n",
        "                s = 10, alpha = 0.3, grid=True)\n",
        "df_cardio.plot.line('age', 'modeloPresionSis', \n",
        "                   c='r', label='Regresión lineal', ax=ax);  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuwsPV01I2f4"
      },
      "source": [
        "Por último, para interpretar este resultado calcularemos el [**coeficiente de determinación $R^2$**](https://es.wikipedia.org/wiki/Coeficiente_de_determinaci%C3%B3n), que es igual al coeficiente de correlación elevado al cuadrado. El coeficiente de determinación determina la calidad del modelo para replicar los resultados, y la proporción de variación de los resultados que puede explicarse por el modelo. El $R^2$ toma valores entre 0.0 y 1.0. Mientras mejor sea el modelo, el valor de $R^2$ será mayor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW_cluxltmVC"
      },
      "source": [
        "print(f\"R^2 = {corr**2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZFbKsJ3KDnw"
      },
      "source": [
        "En este caso vemos que el $R^2$ es bajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzxvJzCWFF0y"
      },
      "source": [
        "**II. Usando `statsmodels`**\n",
        "***\n",
        "\n",
        "La librería **`statsmodels`** no solo permite replicar el resultado anterior al modelar la relación entre dos variables, sino que permite construir modelos más generales donde se involucren más variables. A continuación usaremos las siguientes funciones:\n",
        "\n",
        "* [**`statsmodels.regression.linear_model.OLS.from_formula`**](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.from_formula.html): Crea un modelo a partir de una fórmula y un *DataDrame*.\n",
        "* [**`statsmodels.formula.api.ols`**](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html): Crea un modelo a partir de una fórmula y un *DataDrame* (otra forma).\n",
        "* [**`statsmodels.regression.linear_model.OLS.fit`**](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.fit.html): Calcula los parámetros del modelo.\n",
        "* [**`statsmodels.regression.linear_model.OLSResults.summary`**](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.summary.html): Presenta los resultados del modelo.\n",
        "* [**`statsmodels.regression.linear_model.OLS.predict`**](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.predict.html): Calcula las predicciones del modelo.\n",
        "\n",
        "A continuación vamos a recrear los resultados que habíamos obtenido con **`SciPy`** anteriormente:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQyaIqPFOSt"
      },
      "source": [
        "# La fórmula se pone de la forma: VARIABLE_DEPENDIENTE ~ VARIABLE_INDEPENDIENTE \n",
        "model = sm.OLS.from_formula(\"sysBP ~ age\", data=df_cardio)\n",
        "\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bTJ54HSJiM"
      },
      "source": [
        "De todos estos resultados los más interesantes son:\n",
        "* **`R-squared`** (en la parte superior derecha): Coeficiente de determinación.\n",
        "* **`Intercept`:** Intercepto de la recta.\n",
        "* **`age`**: Pendiente de la recta.\n",
        "\n",
        "Además, observe que por cada uno de los coeficientes se calcula su error estándar, estadístico **`t`**, **p-valor** (dos colas) y el intervalo de confianza del parámetro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ClSkVl2TXo6"
      },
      "source": [
        "Podemos obtener el mismo resultado usando **`statsmodels.formula.api` (`smf`)**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuy2BJXUThiQ"
      },
      "source": [
        "# La fórmula se pone de la forma: VARIABLE_DEPENDIENTE ~ VARIABLE_INDEPENDIENTE \n",
        "model = smf.ols(\"sysBP ~ age\", data=df_cardio).fit() # Aquí creamos el modelo y calculamos sus parámetros directamente con fit()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kuc3hsU-rje"
      },
      "source": [
        "## **2.3. Regresión multilineal**\n",
        "---\n",
        "\n",
        "Hasta ahora hemos modelado la relación de una única variable independiente con una variable dependiente. Sin embargo, normalmente en las relaciones entre variables se involucran otros aspectos que hacen que dichas relaciones no sean tan directas. La **regresión lineal múltiple** es un modelo estadístico que examina la relación lineal entre más de dos variables, donde una es la variable dependiente o de respuesta, y las otras son variables independientes de predicción continuas o categóricas. La función del modelo de regresión lineal múltiple es muy similar a la función del modelo de regresión lineal de dos variables, con un coeficiente y una variable en la fórmula por cada variable predictora adicional. Así, el modelo general podría ser formulado de la siguiente manera:\n",
        "\n",
        "$y = {\\beta}_{0} +{\\beta}_{1} x_1  + {\\beta}_{2} x_2 + ... + {\\beta}_{i} x_i + ... + u$\n",
        "\n",
        "Por ejemplo, la presión arterial sistólica además de la edad, puede estar relacionada con otras variables tales como: el sexo, si es fumador o no, su índice de masa corporal (BMI), etc.\n",
        "\n",
        "Veamos las correlacciones de las demás variables con respecto a la variable **`sysBP`** (presión sistólica):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkL587uYb2_N"
      },
      "source": [
        "# Obtenemos la matriz de correlacion, seleccionamos la variable de interés 'sysBP',\n",
        "# Después, ordenamos los valores, y los presentamos en orden ascendente\n",
        "\n",
        "df_cardio.corr()['sysBP'].sort_values()[::-1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTLT_wIScl-3"
      },
      "source": [
        "Podemos ver que hay variables como **`diaBP`** (presión arterial diastólica), **`prevalentHyp`** (si el paciente era o no hipertenso), **`BMI`** (índice de masa corporal) que tienen una correlación no despreciable con nuestra variable de interés (**`sysBP`**). \n",
        "\n",
        "A continuación crearemos varios modelos, donde la variable dependiente es **`sysBP`** pero en este caso tendremos más de una variable independiente.\n",
        "\n",
        "En primer lugar, veamos los resultados si las variables dependientes fueran **`age`** y **`prevalentHP`**: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slHY6IyQy3Rw"
      },
      "source": [
        "# La fórmula se pone de la forma: VARIABLE_DEPENDIENTE ~ VARIABLE_INDEPENDIENTE1 + VARIABLE_INDEPENDIENTE2 \n",
        "model = sm.OLS.from_formula(\"sysBP ~ age + prevalentHyp\", data=df_cardio)\n",
        "\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARuqb6IcecL-"
      },
      "source": [
        "Observe que el $R^2$ se incrementó hasta $0.521$. Esto quiere decir que incluyendo el valor nominal que indica si el paciente era o no hipertenso el modelo mejoró notablemente. \n",
        "\n",
        "> **Nota:** La sintaxis de la fórmula **`sysBP ~ age + prevalentHyp`** en la celda anterior significa que estas dos variables se usarán para construir el modelo con sus dos respectivos coeficientes más un coeficiente de intercepto. Además, también nos dice que estas variables están incluidas en el modelo como predictores de la presión arterial sistólica.\n",
        "\n",
        "Además, es muy importante considerar que el coeficiente de edad de $0,49$ sólo tiene sentido cuando se comparan dos personas que tengan el mismo **`prevalentHyp`**, y el coeficiente de **`prevalentHyp`** de $30.46$ sólo tiene sentido cuando se comparan dos personas de la misma edad.\n",
        "\n",
        "Tenga en cuenta que en este caso, pese a ser nominal, dicha variable estaba previamente codificada con **`0`** y **`1`**. No obstante, si hubiese sido un valor categórico también hubiese sido posible crear el modelo. Por ejemplo, hagamos un ejemplo con la variable **`male`**, transformándola previamente de su codificación a valores categóricos: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQy0pk6fYkO"
      },
      "source": [
        "df_cardio.loc[df_cardio['male'] == 1, 'male'] = 'Hombre' \n",
        "df_cardio.loc[df_cardio['male'] == 0, 'male'] = 'Mujer'\n",
        "df_cardio.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x6EC8rHyws_"
      },
      "source": [
        "model = sm.OLS.from_formula(\"sysBP ~ age + prevalentHyp + male\", data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyWRhafhi6FV"
      },
      "source": [
        "De esta forma, el modelo calcula coeficientes adicionales para dicha variable categórica, diferenciando cada uno de sus 2 posibles valores. \n",
        "\n",
        "Finalmente, creemos un modelo con un mayor número de variables independientes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R73rbyZzFXmu"
      },
      "source": [
        "model = sm.OLS.from_formula(\"sysBP ~ age + prevalentHyp + male + diaBP + BMI\", \n",
        "                            data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N68nVDokJEO"
      },
      "source": [
        "Observe que se incrementó el $R^2$ aún más. También, la mayoría de las variables independientes aportan al resultado. Sin embargo, al examinar el coeficiente y el p-valor de la variable **`BMI`** podemos observar que no es significativo. Por lo tanto, crearemos un modelo final sin considerar dicha variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agz8bGJ9k0rX"
      },
      "source": [
        "model = sm.OLS.from_formula(\"sysBP ~ age + prevalentHyp + male + diaBP\", \n",
        "                            data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSMWG_Cqk3Ay"
      },
      "source": [
        "Obtenemos el mismo coeficiente de determinación $R^2$ que antes ($0.726$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bijydo-h_AYW"
      },
      "source": [
        "## **2.4. Regresión logística**\n",
        "---\n",
        "\n",
        "La regresión logística es un modelo estadístico que examina la relación entre dos variables con un modelo matemático que simula un modelo logístico binario, empleado para modelar la probabilidad de ocurrencia de un evento en función de variables independientes.\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?export=view&id=1e4PwC_aQJt-nuadUH2bvgob15Q9Vuq0X\" alt = \"Regresión logística\" width = \"65%\">  </img>\n",
        "\n",
        "La librería **`statsmodels`** permite construir modelos de este tipo mediante las siguientes funciones:\n",
        "\n",
        "* [**`statsmodels.GLM.from_formula`**](https://www.statsmodels.org/devel/examples/notebooks/generated/glm_formula.html).\n",
        "* [**`statsmodels.discrete.discrete_model.Logit`**](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.fit.html).\n",
        "\n",
        "Por ejemplo, el objetivo de la clasificación de los datos con que hemos trabajado es predecir si el paciente tiene un riesgo de padecer una futura enfermedad coronaria (CHD) dentro de 10 años. Esta es la variable **`TenYearCHD`** del dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tDNJqh5GLoC"
      },
      "source": [
        "**Regresión logística**\n",
        "\n",
        "```\n",
        "model = sm.GLM.from_formula( \"V_DEP ~ V_IND1\",\n",
        "                  family=sm.families.Binomial(),\n",
        "                    data=da)\n",
        "```\n",
        "\n",
        "**Regresión logística con 2 variables independientes**\n",
        "\n",
        "```\n",
        "model = sm.GLM.from_formula( \"V_DEP ~ V_IND1 + V_IND2\", \n",
        "                  family = sm.families.Binomial(), \n",
        "                    data = da)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBHqLag2Gbnu"
      },
      "source": [
        "model = sm.GLM.from_formula(\"TenYearCHD ~ sysBP\", family=sm.families.Binomial(), data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDrgkqJFoT9K"
      },
      "source": [
        "model = sm.GLM.from_formula(\"TenYearCHD ~ sysBP + male + age\", family=sm.families.Binomial(), data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5_33e1jy-SG"
      },
      "source": [
        "Otra forma de hacerlo es con la función **`smf.logit`**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAGRuTJGyrNr"
      },
      "source": [
        "model = smf.logit(\"TenYearCHD ~ sysBP + male + age\", data=df_cardio)\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OdT_x_Jiz1o"
      },
      "source": [
        "Finalmente podemos obtener los coeficientes del modelo con el atributo **`result.params`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TYnU6DeiyGz"
      },
      "source": [
        "result.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r5hSQAz6d-g"
      },
      "source": [
        "## **Recursos adicionales**\n",
        "---\n",
        "Para profundizar mucho más, le recomendamos los siguientes recursos adicionales:\n",
        "\n",
        "*  [University of Michigan (Coursera) - Fitting Statistical Models to Data with Python](https://www.coursera.org/learn/fitting-statistical-models-data-python)\n",
        "*  [Kaggle - Correlation (Pearson, Spearman and Kendall)](https://www.kaggle.com/kiyoung1027/correlation-pearson-spearman-and-kendall/report)\n",
        "*  [towards data science - Simple and Multiple Linear Regression in Python](https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9)\n",
        "*  [Data Vedas - Correlation Coefficients](https://www.datavedas.com/correlation-coefficients/)\n",
        "*  [Mike Freeman - Binary Predictions Metrics](http://mfviz.com/binary-predictions/)\n",
        "*  [Mike Freeman - An Introduction to Hierarchical Modeling](http://mfviz.com/hierarchical-models/)\n",
        "*  [Joaquín Amat Rodrigo (Ciencia de datos) - Correlación lineal y Regresión lineal simple](https://www.cienciadedatos.net/documentos/24_correlacion_y_regresion_lineal)\n",
        "*  [statsmodels documentation](https://www.statsmodels.org/stable/index.html)\n",
        "*  [SciPy Statistical functions (scipy.stats)](https://docs.scipy.org/doc/scipy/reference/stats.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4VavQ3wgMGo"
      },
      "source": [
        "## **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "  - Alberto Nicolai Romero Martínez\n",
        "  - Miguel Angel Ortiz Marín\n",
        "\n",
        "* **Asistentes docentes (pequeñas correcciones):**\n",
        "  - Joseph Alejandro Gallego Mejía\n",
        "\n",
        "* **Fe de erratas:**\n",
        " * Punto 1.3.3 Coeficiente de correlación de Kendall: el coeficiente de correlación de Kendall es una prueba de dos colas, por lo que la significancia se debe dividir por 2 al compararlo con el p-valor\n",
        " * Punto 1.3.2 Prueba de Levene: esta prueba tiene como hipótesis nula que las varianzas son homogéneas, por lo tanto un p-valor > significancia nos dirá que no podemos rechazar la hipótesis nula.\n",
        " * Punto 2.2 Nota aclaratoria: el modelo de regresión lineal suma las variables linealmente multiplicadas cada una con un coeficiente y al final sumando un coeficiente de intercepto.\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ]
}